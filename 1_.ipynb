{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- spark is an open source unified computing engine with set of libraries for parallel processing on computer cluster\n",
    "- spark components\n",
    "   - low level api - RDD & distributed variables\n",
    "   - structured api- Dataframes,datasets and sql\n",
    "   - libraries and ecosystem,structured streaming and advanced analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/imps.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/eg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- let an instructor asks group of individuals (A,B,C,..) to count marbles present in different pouches "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- let each pouch are given to A,B,D,E. and asked to count\n",
    "- A reports 10 ,B reports 5,D reports 15, E reports 25 -> now instructor have **local count**\n",
    "- instructor asks G to go and collect total count (global count)\n",
    "- G reports 55 to instructor\n",
    "- in between 'local count' <-> 'global count' we have a shuffle stage\n",
    "-  data was shuffled between groups \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- instructor is **Driver**\n",
    "- each group is **Executer**\n",
    "- the counting done by each individual is **Task**\n",
    "- local count <-> global count \n",
    "   - 2 stages\n",
    "   -  when ever there is a **shuffle** in job ,the job will be divided into **stages**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Driver\n",
    "    - heart \n",
    "    - maintain all relevant information that is required for executors\n",
    "    - analyzes,distributes,schedules the work\n",
    "- Executer\n",
    "    - executes the code\n",
    "    - respond to driver with execution status.\n",
    "- user assigns **JOBS** to Driver \n",
    "  - Driver inturn analyze,distributes and breaks down jobs into stages,tasks and assign it to executers\n",
    "  - executors are basically jvm processes that run in cluster machines and it consist of cores.\n",
    "  - here we have 6 cores and 3 executors\n",
    "  - all these cores can run in parallel and perform 6 task at a time\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- to allow every executors to work in parallel,spark breaks down the data into chunks called **partitions**\n",
    "- bag of marbles contained in pouches can be considered as partition \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- transformation\n",
    " - the instruction or code to modify and transform data is known as transformation.\n",
    " - Eg: select,where,groupBy\n",
    "- 2 Type of transformation\n",
    "  - **Narrow Transformation**\n",
    "  - **Wide Transformation** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ..... ->(transformation) ->.....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data  -> (where sal >10000) -> Data\n",
    "- Data -> (select name,depid,salary)-> Data\n",
    "- Data -> (group By deptid) -> Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Narrow transformation\n",
    "   - a data partition contributes to only one data partition -> **One TO One** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wide transformation\n",
    "  - a data partition contributes to many partitions -> **One To N**\n",
    "  - data from one partition moved to multiple partitions ->this is also called as shuffle\n",
    "  - wide transformation lead to shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Actions**\n",
    "- to trigger the execution we need to call an Action\n",
    "- this basically executes the plan created by transformation \n",
    "- Action are of three types:\n",
    "   1. View data in console\n",
    "   2. collect data to native language\n",
    "   3. write data to output data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- spark prefers lazy evaluation \n",
    "   - spark will wait till last moment to execute the graph of computation\n",
    "   - this allows spark to optimize ,plan and use the resources properly for execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Spark Session**\n",
    "  1. the driver process is known as Spark Session\n",
    "  2. it is the entry point for a spark execution\n",
    "  3. the spark session instances executes the code in the cluster\n",
    "  4. and the relation is one-to-one ,for 1 spark application we will have 1 spark session instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "- **dataframes**\n",
    "  - dataframe is the most common structured api, represented like a table\n",
    "  - dataframe has schema,which is meta data for the columns\n",
    "  - data in dataframes are partitions\n",
    "  - dataframes are immutable\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- structured api execution plan\n",
    "   1. logical planning\n",
    "   2. physical planning\n",
    "\n",
    "\n",
    "- ![](imgs/plan.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Logical planning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/log.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- once code is supplied by user -> spark creates unresolved logical plan -> this unresolved logical plan is validated with catalog for column names and table names\n",
    "- once validated spark creates a resolved logical plan  - > is taken to catalyst optimizer -> which does the whole optimization for logical planning\n",
    "- generates optimized logical plan ->DAG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/PHY.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- once optimized logical plan is ready spark generates multiple physical plan based on cluster and physical configuration \n",
    "- this physical plan run against cost model(generates cost of each plan)\n",
    "- spark selects best physical plan -> is send to cluster for execution\n",
    "- once executer recieves physical plan,they run physical plan against data partitions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Hands On"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SparkSession\n",
    "- create dataframe&columns\n",
    "- spark ui\n",
    "- introduction to transformation & actions\n",
    "- pyspark shell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
